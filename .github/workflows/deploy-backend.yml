name: deploy-backend
# Description: Deploys backend resources to the selected environment. 
# Allows selection of branch for deployment - choose 'main' for production deployments 
# or a feature branch for testing.

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        type: environment
      region:
        description: 'AWS Region'
        required: true
        type: choice
        options:
          - 'us-east-1'
      customer_id:
        description: 'Customer ID'
        required: true
        type: string
        default: 'orb'
      project_id:
        description: 'Project ID'
        required: true
        type: string
        default: 'integration-hub'
      sms_origination_number:
        description: 'SMS Origination Number'
        required: true
        type: string
        default: '+12898190331'

jobs:

  deploy-backend-stacks:
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}

    steps:
      - name: Checkout repo for branch listing
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pipenv
          cd schemas
          pipenv install

      - name: Generate schema files
        run: |
          cd schemas
          pipenv run python generate.py
          
      - name: Validate GraphQL schema
        run: |
          echo "Validating GraphQL schema..."
          
          # Find the latest generated appsync schema file
          SCHEMA_FILE=$(find ./backend/infrastructure/cloudformation -name "appsync_*.graphql" | sort -r | head -1)
          
          if [ -z "$SCHEMA_FILE" ]; then
            echo "ERROR: No appsync_*.graphql file found. Schema generation may have failed."
            exit 1
          fi
          
          echo "Using schema file: $SCHEMA_FILE"
          
          # Basic syntax check - if the file has GraphQL type definitions
          if ! grep -q "type " "$SCHEMA_FILE"; then
            echo "ERROR: Schema file appears to be empty or invalid. Missing type definitions."
            exit 1
          fi
          
          # Check for other required GraphQL elements
          if ! grep -q "schema {" "$SCHEMA_FILE"; then
            echo "WARNING: Schema file may be missing schema definition."
          fi
          
          # Check file size is reasonable (not empty, not too small)
          FILE_SIZE=$(wc -c < "$SCHEMA_FILE")
          if [ "$FILE_SIZE" -lt 100 ]; then
            echo "WARNING: Schema file is suspiciously small ($FILE_SIZE bytes)."
          fi
          
          # Extract the filename for use in later steps
          SCHEMA_FILENAME=$(basename "$SCHEMA_FILE")
          echo "schema_filename=$SCHEMA_FILENAME" >> $GITHUB_OUTPUT
          
          echo "Schema validation complete."

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ inputs.region }}

      - name: Install AWS SAM CLI
        run: |
          # Add AWS SAM CLI repository
          curl -L https://github.com/aws/aws-sam-cli/releases/latest/download/aws-sam-cli-linux-x86_64.zip -o aws-sam-cli-linux-x86_64.zip
          unzip aws-sam-cli-linux-x86_64.zip -d sam-installation
          sudo ./sam-installation/install --update
          sam --version
          # Clean up
          rm -rf aws-sam-cli-linux-x86_64.zip sam-installation

      - name: Upload schema to S3
        run: |
          # Find the latest generated appsync schema file
          SCHEMA_FILE=$(find . -name "appsync_*.graphql" | sort -r | head -1)
          SCHEMA_FILENAME=$(basename "$SCHEMA_FILE")
          
          echo "Uploading schema file: $SCHEMA_FILENAME"
          
          # Create a clean copy without BOM
          echo "Creating clean UTF-8 copy without BOM..."
          CLEAN_FILE="${SCHEMA_FILE}.clean"
          
          # Read the file and write it back as clean UTF-8 without BOM
          cat "$SCHEMA_FILE" | tr -d '\r' | sed 's/^\xEF\xBB\xBF//' > "$CLEAN_FILE"
          mv "$CLEAN_FILE" "$SCHEMA_FILE"
          
          # Upload the schema file to S3 with explicit content type
          aws s3 cp "$SCHEMA_FILE" \
            s3://${{ inputs.customer_id }}-${{ inputs.project_id }}-build-templates/$SCHEMA_FILENAME \
            --content-type "text/plain; charset=utf-8"

        working-directory: ./backend/infrastructure/cloudformation

      - name: Deploy All Stacks
        run: |
          
          for stack in bootstrap cognito dynamodb lambdas appsync; do
            echo "Deploying $stack stack..."
            
            # Special handling for AppSync stack
            if [ "$stack" == "appsync" ]; then
              # Find the latest generated schema file
              SCHEMA_FILE=$(find . -name "appsync_*.graphql" | sort -r | head -1)
              SCHEMA_FILENAME=$(basename "$SCHEMA_FILE")
              
              # Create a clean copy for deployment
              echo "Preparing schema file for AppSync deployment..."
              DEPLOY_FILE="${SCHEMA_FILE}.deploy"
              cat "$SCHEMA_FILE" | tr -d '\r' | sed 's/^\xEF\xBB\xBF//' > "$DEPLOY_FILE"
              mv "$DEPLOY_FILE" "$SCHEMA_FILE"
              
              # Set the schema filename for deployment
              PARAMS="$PARAMS SchemaS3Key=$SCHEMA_FILENAME"
            fi
            
            echo "Building ${stack} stack..."
            sam build --template ${stack}.yml || {
              echo "ERROR: Failed to build ${stack} stack"
              exit 1
            }
          
            echo "Packaging ${stack} stack..."
            sam package \
              --template-file ${stack}.yml \
              --s3-bucket ${{ inputs.customer_id }}-${{ inputs.project_id }}-build-artifacts \
              --output-template-file ${stack}-packaged.yml || {
                echo "ERROR: Failed to package ${stack} stack"
                exit 1
              }
          
            # Add an override for the schema location
            PARAMS="Environment=${{ inputs.environment }} CustomerId=${{ inputs.customer_id }} ProjectId=${{ inputs.project_id }}"
            if [ "$stack" == "appsync" ]; then
              # Find the latest generated schema file
              SCHEMA_FILE=$(find . -name "appsync_*.graphql" | sort -r | head -1)
              SCHEMA_FILENAME=$(basename "$SCHEMA_FILE")
              PARAMS="$PARAMS SchemaS3Key=$SCHEMA_FILENAME"
              echo "Using schema: $SCHEMA_FILENAME for AppSync stack"
            fi
            if [ "$stack" == "lambdas" ]; then
              PARAMS="$PARAMS SMSOriginationNumber=${{ inputs.sms_origination_number }}"
              echo "Using SMS Origination Number: ${{ inputs.sms_origination_number }} for Lambdas stack"
            fi
                    
            echo "Deploying ${stack} stack with parameters: $PARAMS"
            sam deploy \
              --template-file ${stack}-packaged.yml \
              --s3-bucket ${{ inputs.customer_id }}-${{ inputs.project_id }}-build-artifacts \
              --stack-name ${{ inputs.customer_id }}-${{ inputs.project_id }}-${stack} \
              --capabilities CAPABILITY_NAMED_IAM \
              --no-fail-on-empty-changeset \
              --parameter-overrides $PARAMS || {
                echo "ERROR: Failed to deploy ${stack} stack"
                exit 1
              }
          
            echo "Uploading packaged template to S3..."
            aws s3 cp ${stack}-packaged.yml \
              s3://${{ inputs.customer_id }}-${{ inputs.project_id }}-build-templates/${stack}-packaged.yml || {
                echo "ERROR: Failed to upload packaged template for ${stack} stack"
                exit 1
              }
          
          done
        working-directory: ./backend/infrastructure/cloudformation
